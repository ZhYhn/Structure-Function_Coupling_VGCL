{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8627d44f-aa71-4cbc-9253-89520fbff9a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "from scipy import stats\n",
    "from scipy.sparse.csgraph import shortest_path\n",
    "from scipy.linalg import expm\n",
    "from scipy.spatial.distance import cdist\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b1a46d9-fbaa-4264-ac8e-4e6fccef882e",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read the tract length of tractography (using for constructing the consensus matrix)\n",
    "\n",
    "t_subjs = set(pd.read_csv(r\"D:\\Download\\SFC\\SFC_HCP\\4_Validation\\individual_VGAE\\sfc_network_df.csv\").Subject.apply(lambda x: x[:6]))\n",
    "h5_path = r\"D:\\Download\\SFC\\SFC_HCP\\2_Preprocess\\1_SC\\sc_matlab\\individualConnectivity_tractLength.mat\"\n",
    "lengths = []\n",
    "with h5py.File(h5_path, \"r\") as f:\n",
    "    subjects = [str(subject) for subject in f['subjectIDs'][0]]\n",
    "    for i, subject in enumerate(subjects):\n",
    "        if subject in t_subjs:\n",
    "            lengths.append(f['rawTractLengths'][i].T)\n",
    "lengths = np.array(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9d31703-d11b-4825-88ca-318abe9c72fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# This function is used to construct a consensus matrix (reference: https://doi.org/10.1073/pnas.1903403116)\n",
    "# But because we need individual sfc by regression approach, it was not used.\n",
    "\n",
    "def build_consensus_matrix(sc, lengths):\n",
    "\n",
    "    n_subjects = sc.shape[0]\n",
    "\n",
    "    consensus_sc = np.zeros((360, 360))\n",
    "    \n",
    "    densities = []\n",
    "    for s in range(n_subjects):\n",
    "        upper_tri = sc[s][np.triu_indices(360, k=1)]\n",
    "        densities.append(np.mean(upper_tri))\n",
    "    n_bins = int(np.sqrt(np.mean(densities) * n_subjects))\n",
    "    n_bins = max(2, n_bins)\n",
    "    \n",
    "    for connection_type in ['intra_left', 'intra_right', 'inter']:\n",
    "        if connection_type == 'intra_left':\n",
    "            mask_i, mask_j = np.meshgrid(range(180), range(180), indexing='ij')\n",
    "            mask = mask_i < mask_j\n",
    "        elif connection_type == 'intra_right':\n",
    "            mask_i, mask_j = np.meshgrid(range(180, 360), range(180, 360), indexing='ij')\n",
    "            mask = mask_i < mask_j\n",
    "        else:\n",
    "            mask_i, mask_j = np.meshgrid(range(180), range(180, 360), indexing='ij')\n",
    "            mask = np.ones_like(mask_i, dtype=bool)\n",
    "    \n",
    "        connections = []\n",
    "        for i, j in zip(mask_i[mask], mask_j[mask]):\n",
    "            node_i, node_j = i, j\n",
    "            frequency = np.sum([sc[s, node_i, node_j] for s in range(n_subjects)])\n",
    "            if frequency > 0:\n",
    "                avg_length = np.mean([lengths[s, node_i, node_j] for s in range(n_subjects) if sc[s, node_i, node_j] > 0])\n",
    "                connections.append({\n",
    "                    'i': node_i,\n",
    "                    'j': node_j,\n",
    "                    'frequency': frequency,\n",
    "                    'length': avg_length\n",
    "                })\n",
    "        if not connections:\n",
    "            continue\n",
    "    \n",
    "        connection_lengths = [conn['length'] for conn in connections]\n",
    "        bin_edges = stats.mstats.mquantiles(connection_lengths, np.linspace(0, 1, n_bins + 1))\n",
    "        bin_edges[0] = min(connection_lengths) - 1e-6\n",
    "        bin_edges[-1] = max(connection_lengths) + 1e-6\n",
    "        \n",
    "        binned_connections = [[] for _ in range(n_bins)]\n",
    "        for conn in connections:\n",
    "            bin_idx = np.digitize(conn['length'], bin_edges) - 1\n",
    "            bin_idx = max(0, min(bin_idx, n_bins - 1))\n",
    "            binned_connections[bin_idx].append(conn)\n",
    "            \n",
    "        for bin_idx, bin_conns in enumerate(binned_connections):\n",
    "            if not bin_conns:\n",
    "                continue\n",
    "                \n",
    "            bin_frequencies = [conn['frequency'] for conn in bin_conns]\n",
    "            k = int(np.mean(bin_frequencies))\n",
    "            k = max(1, k)\n",
    "            \n",
    "            bin_conns_sorted = sorted(bin_conns, key=lambda x: x['frequency'], reverse=True)\n",
    "            selected_conns = bin_conns_sorted[:k]\n",
    "            for conn in selected_conns:\n",
    "                consensus_sc[conn['i'], conn['j']] = 1\n",
    "                consensus_sc[conn['j'], conn['i']] = 1\n",
    "\n",
    "    return consensus_sc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ca9f611-bdd4-408f-b583-56e8ffb10bfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 Read sc\n",
    "\n",
    "scs = []\n",
    "for root, dirs, files in os.walk(r\"D:\\Download\\SFC\\SFC_HCP\\3_Modeling\\2_modeling\\sc_dataset\\raw\"):\n",
    "    for file in files:\n",
    "        sc = np.load(os.path.join(root, file))\n",
    "        \n",
    "        mask = np.eye(sc.shape[0], dtype=bool)\n",
    "        sc[mask] = 0\n",
    "        threshold = np.quantile(sc[~mask], 0.932)\n",
    "        sc[sc < threshold] = 0\n",
    "        sc[sc >= threshold] = 1\n",
    "        \n",
    "        scs.append(sc)\n",
    "scs = np.array(scs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47ae12f9-c70c-424e-aee9-94c482b65372",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 Read fc\n",
    "\n",
    "fcs = []\n",
    "for root, dirs, files in os.walk(r\"D:\\Download\\SFC\\SFC_HCP\\3_Modeling\\2_modeling\\fc_dataset\\raw\"):\n",
    "    for file in files:\n",
    "        path_fc = os.path.join(root, file)\n",
    "        fcs.append(np.load(path_fc))\n",
    "fcs = np.array(fcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97e28d3b-917e-40b0-aec0-79d75b3fd6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 Obtain the centroid coordinates for calculating the distance between brain regions\n",
    "\n",
    "centroids = np.load(r\"D:\\Download\\SFC\\SFC_HCP\\3_Modeling\\1_get_centroids\\centroids\\HCP_MMP1_centroids.npy\")\n",
    "euclidean_distance = cdist(centroids, centroids, metric='euclidean')\n",
    "mask = np.eye(360, dtype=bool)\n",
    "euclidean_distance = (euclidean_distance - euclidean_distance[~mask].mean()) / euclidean_distance[~mask].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "af7952bd-8f6d-45bc-a8db-cec4676c2cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function is used to obtain the shortest path and communicability (used as independent variable)\n",
    "\n",
    "def getX(sc):\n",
    "    path_length = shortest_path(sc, directed=False, method='D', unweighted=True)\n",
    "    path_length[path_length == np.inf] = 361\n",
    "    path_length = (path_length - path_length[~mask].mean()) / path_length[~mask].std()\n",
    "    max_degree = np.max(np.sum(sc, axis=1))\n",
    "    communicability = np.log(expm(sc / max_degree) + 1e-8)\n",
    "    communicability = (communicability - communicability[~mask].mean()) / communicability[~mask].std()\n",
    "    return path_length, communicability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0bce0598-28cd-4035-a510-b0fd8927d664",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Calculate group sfc (but not used for contrast)\n",
    "\n",
    "consensus_fc = fcs.mean(axis=0)\n",
    "\n",
    "consensus_sc = build_consensus_matrix(scs, lengths)\n",
    "\n",
    "consensus_path_length, consensus_communicability = getX(consensus_sc)\n",
    "\n",
    "consensus_regression_sfc = np.zeros(360)\n",
    "\n",
    "for node_i in range(360):\n",
    "    \n",
    "    y_train = np.delete(consensus_fc[node_i, :], node_i)\n",
    "    X_euclidean_train = np.delete(euclidean_distance[node_i, :], node_i)\n",
    "    X_path_train = np.delete(consensus_path_length[node_i, :], node_i)\n",
    "    X_comm_train = np.delete(consensus_communicability[node_i, :], node_i)\n",
    "    \n",
    "    X_train = np.column_stack([X_euclidean_train, X_path_train, X_comm_train])\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_train)\n",
    "    \n",
    "    r2 = r2_score(y_train, y_pred)\n",
    "    n, p = 359, 3\n",
    "    adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "\n",
    "    consensus_regression_sfc[node_i] = adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0463711f-2dc4-4ff3-a4a0-0b0e2a560f2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 998/998 [1:41:17<00:00,  6.09s/it]\n"
     ]
    }
   ],
   "source": [
    "# 4 Calculate individual sfc\n",
    "\n",
    "regression_sfc = np.zeros((3992, 360))\n",
    "\n",
    "for s in tqdm(range(998)):\n",
    "    path_length, communicability = getX(scs[s])\n",
    "    \n",
    "    for i in range(4):\n",
    "        fc = fcs[4*s+i]\n",
    "        \n",
    "        for node_i in range(360):\n",
    "            \n",
    "            y_train = np.delete(fc[node_i, :], node_i)\n",
    "            X_euclidean_train = np.delete(euclidean_distance[node_i, :], node_i)\n",
    "            X_path_train = np.delete(path_length[node_i, :], node_i)\n",
    "            X_comm_train = np.delete(communicability[node_i, :], node_i)\n",
    "            \n",
    "            X_train = np.column_stack([X_euclidean_train, X_path_train, X_comm_train])\n",
    "            \n",
    "            model = LinearRegression()\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred = model.predict(X_train)\n",
    "            \n",
    "            r2 = r2_score(y_train, y_pred)\n",
    "            n, p = 359, 3\n",
    "            adjusted_r2 = 1 - (1 - r2) * (n - 1) / (n - p - 1)\n",
    "            \n",
    "            regression_sfc[4*s+i, node_i] = adjusted_r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "171113bf-636b-45f5-9774-fadb3ed4612d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgcl_sfc = pd.read_csv(r\"D:\\Download\\SFC\\SFC_HCP\\6_Contrast\\vgcl_individual_sfc.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4f139a9-13e4-411b-80a6-d88d08215e7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_sfc = vgcl_sfc.copy()\n",
    "regr_sfc.iloc[:, 3:] = regression_sfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3976ae5f-70be-4c2d-bc1b-8a86a24fcfdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr_sfc.to_csv('D:\\\\Download\\\\regr_individual_sfc.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c1def5-0f09-487b-b29c-4ef301d40217",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf3f2c5-9726-4e07-8c9c-c89a9b59f921",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22cac3c-bca8-4616-b514-c423a3f6b6ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
